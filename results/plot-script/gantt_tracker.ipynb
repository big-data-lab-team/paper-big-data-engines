{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    # Simplify the workers name\n",
    "    df[\"worker_name\"] = df.worker.map(str).map(\n",
    "        lambda x: \"\".join(x.split(\"-\")[1:]).split(\".\")[0]\n",
    "    )\n",
    "    \n",
    "    # Rename function\n",
    "    func_map = {\n",
    "        'read_img': 'Read',\n",
    "        \"save_results\": \"Write\",\n",
    "        'save_histogram': 'Write',\n",
    "        \"flatten\": \"Compute\",\n",
    "        \"increment\": \"Compute\",\n",
    "        'calculate_histogram': 'Compute',\n",
    "        'combine_histogram': 'Compute',\n",
    "        \"run_participant\": \"Participant\",\n",
    "        \"run_group\": \"Group\",\n",
    "        \"serialize\": \"serialize\",\n",
    "        \"deserialize\": \"deserialize\"\n",
    "    }\n",
    "#     df.func = df.func.apply(lambda x: func_map[x])\n",
    "    \n",
    "\n",
    "    # Simplify the thread number for each worker\n",
    "    thread_worker = {\n",
    "        w + \"::\" + str(t): i + 1\n",
    "        for w in df.worker_name.unique()\n",
    "        for i, t in enumerate(df[df.worker_name == w].thread.unique())\n",
    "    }\n",
    "    df[\"worker_thread\"] = df.worker_name.map(str) + \"::\" + df.thread.map(str)\n",
    "    df[\"thread_number\"] = df.worker_thread.map(lambda x: thread_worker[x])\n",
    "    df[\"worker_thread\"] = (\n",
    "        df.worker_name.map(str) + \"::thread\" + df.thread_number.map(str)\n",
    "    )\n",
    "    df = df.sort_values(by=[\"worker_name\", \"thread_number\"], ascending=[False, True])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gantt_tracker(df, *,pre_process=None, group, x_limit=None, save_name=None, framework,\n",
    "                 xaxis_label, yaxis_label):\n",
    "    \"\"\"Create an interactive gantt chart from a pandas dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.Dataframe\n",
    "        Data to plot.\n",
    "    pre_process : func\n",
    "        Function to pre-process the dataframe.\n",
    "    group : string, optional\n",
    "        Column name of the element to group together.  \n",
    "    x_limit: int, optional\n",
    "        Maximum value for the x axis.\n",
    "    save_name : str, optional\n",
    "        Filename for the gantt chart.\n",
    "    framework : str\n",
    "        Name of the framework from which the data were collected.\n",
    "        Currently only support Dask and Spark.\n",
    "    xaxis_label : str\n",
    "        Label for the x axis.\n",
    "    yaxis_label : str\n",
    "        Label for the y axis.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        DONE\n",
    "    \"\"\"\n",
    "    from bokeh.models import CustomJS, ColumnDataSource, Grid, LinearAxis, Plot, Range1d\n",
    "    from bokeh.models.annotations import Legend, LegendItem\n",
    "    from bokeh.models.glyphs import Quad\n",
    "    from bokeh.models.tools import BoxZoomTool, HoverTool, PanTool, ResetTool, SaveTool, TapTool, WheelZoomTool\n",
    "    from bokeh.io import curdoc, output_file, output_notebook, show\n",
    "    from bokeh.palettes import Colorblind8\n",
    "\n",
    "    # Verify that the framework is supported.\n",
    "    try:\n",
    "        if framework.lower() == 'dask':\n",
    "            pass\n",
    "        elif framework.lower() == 'spark':\n",
    "            try:\n",
    "                if 'process' not in df.columns:\n",
    "                    raise ValueError\n",
    "                df['thread'] = df['process']\n",
    "            except ValueError:\n",
    "                print(f'fatal error : dataframe for spark must contain a process column.')\n",
    "                return\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "    except ValueError:\n",
    "        print(f'fatal error : {framework} is not a supported framework.')\n",
    "        return\n",
    "\n",
    "    # Pre-processing of the dataframe.\n",
    "    if pre_process:\n",
    "        df = pre_process(df)  \n",
    "       \n",
    "    # Make sure the dataframe is value with the function standard.\n",
    "    _MUST_HAVE_COLUMN = ['func', 'start', 'end', 'filename', 'thread', group]\n",
    "    \n",
    "    for column_name in _MUST_HAVE_COLUMN:\n",
    "        try:\n",
    "            if column_name not in df.columns:\n",
    "                raise ValueError\n",
    "        except ValueError:\n",
    "            print(f\"fatal error: the dataframe must contain '{column_name}' after the pre-processing.\")\n",
    "            return\n",
    "\n",
    "    if x_limit is None:\n",
    "        x_limit = df.end.max()\n",
    "        \n",
    "    plot = Plot(plot_width=1250 if save_name is not None else 800,\n",
    "                plot_height=700 if save_name is not None else 600,\n",
    "                x_range=Range1d(-x_limit*0.05,\n",
    "                                x_limit*1.05,\n",
    "                                bounds=\"auto\"),\n",
    "                y_range=Range1d(-max(len(df[group].unique())*0.05, 1),\n",
    "                                len(df[group].unique())*1.05,\n",
    "                                bounds=\"auto\"),\n",
    "               )\n",
    "    \n",
    "    # Group the dataframe by user defined group.\n",
    "    # Create label and associate an y-axis value for each group.\n",
    "    y = 0\n",
    "    labels = []\n",
    "    for i, x in enumerate(df.groupby(group, sort=False)):\n",
    "        labels.append(x[0])\n",
    "        df.loc[df.index.isin(x[1].index), 'bottom'] = y - 0.5\n",
    "        df.loc[df.index.isin(x[1].index), 'top'] = y + 0.5\n",
    "        y += 1\n",
    "\n",
    "    # Define color map for the functions.\n",
    "    glyphs = list()\n",
    "    for i, x in enumerate(sorted(df.func.unique())):\n",
    "        df.loc[df.func == x, 'color'] = Colorblind8[i]\n",
    "        \n",
    "        glyphs.append(\n",
    "            plot.add_glyph(\n",
    "                ColumnDataSource({}),\n",
    "                Quad(fill_color=Colorblind8[i],\n",
    "                     fill_alpha=0.66,\n",
    "                     line_color=Colorblind8[i],\n",
    "                     line_width=0.75,)\n",
    "            )\n",
    "        )\n",
    "    df['original_color'] = df['color']\n",
    "\n",
    "    df['runtime'] = df.end - df.start\n",
    "    \n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    glyph = Quad(left=\"start\",\n",
    "                 right=\"end\",\n",
    "                 top=\"top\",\n",
    "                 bottom=\"bottom\",\n",
    "                 fill_color=\"color\",\n",
    "                 fill_alpha=0.66,\n",
    "                 line_color=\"color\",\n",
    "                 line_width=0.75,)\n",
    "\n",
    "    l = plot.add_glyph(source, glyph)\n",
    "\n",
    "    # Legend\n",
    "    legend = Legend(items=[LegendItem(label=func, renderers=[glyphs[i]]) \n",
    "                               for i, func in enumerate(sorted(df.func.unique()))\n",
    "                          ]\n",
    "                   )\n",
    "    plot.add_layout(legend, 'above')\n",
    "    plot.legend.orientation = 'horizontal'\n",
    "\n",
    "    # Axis\n",
    "    xaxis = LinearAxis()\n",
    "    plot.add_layout(xaxis, 'below')\n",
    "    plot.xaxis.axis_label = xaxis_label\n",
    "\n",
    "    yaxis = LinearAxis()\n",
    "    plot.add_layout(yaxis, 'left')\n",
    "    plot.yaxis.axis_label = yaxis_label\n",
    "    plot.yaxis.major_label_text_font_size = \"6pt\"  # Reduce font size to fit all group together.\n",
    "\n",
    "    plot.add_layout(Grid(dimension=0, ticker=xaxis.ticker))\n",
    "    plot.add_layout(Grid(dimension=1, ticker=yaxis.ticker))\n",
    "\n",
    "    # Set y axis tick label\n",
    "    plot.yaxis.ticker = list(range(0, len(labels)))\n",
    "    plot.yaxis.major_label_overrides = {k: v for k, v in zip(range(0, len(labels)), labels)}\n",
    "\n",
    "    # Hover tool\n",
    "    hover = HoverTool(tooltips=[\n",
    "        ('filename', '@filename'),\n",
    "        ('worker', f'@{group}'),\n",
    "        ('function', '@func'),\n",
    "        ('runtime', '@runtime{%8.3f sec}'),\n",
    "        ('start time', '@start{%8.3f sec}'),\n",
    "        ('end time', '@end{%8.3f sec}'),\n",
    "                                ],\n",
    "                             formatters={\n",
    "        'runtime': 'printf',\n",
    "        'start': 'printf',\n",
    "        'end': 'printf',\n",
    "                             },\n",
    "                     attachment='left')\n",
    "\n",
    "    # Tap tool custom select\n",
    "    cb_click = CustomJS(args=dict(source=source), code=\"\"\"\n",
    "        const inds = source.selected.indices;\n",
    "        const d = source.data;\n",
    "\n",
    "        for (var i = 0; i < d['color'].length; i++){\n",
    "            d['color'][i] = d['original_color'][i]\n",
    "        }\n",
    "\n",
    "        if (inds.length == 0)\n",
    "            return;\n",
    "\n",
    "        same_file = []\n",
    "        for (var i = 0; i < d['color'].length; i++){\n",
    "            if (d['filename'][i] == d['filename'][inds[0]]){\n",
    "                same_file.push(i)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for (var i = 0; i < same_file.length; i++){\n",
    "            d['color'][same_file[i]] = \"firebrick\"\n",
    "        }\n",
    "\n",
    "        source.selected.indices = same_file\n",
    "        source.change.emit();\n",
    "    \"\"\")\n",
    "    source.selected.js_on_change('indices', cb_click)\n",
    "\n",
    "    ## Tool\n",
    "    plot.add_tools(BoxZoomTool())\n",
    "    plot.add_tools(hover)\n",
    "    plot.add_tools(PanTool())\n",
    "    plot.add_tools(ResetTool())\n",
    "    plot.add_tools(SaveTool())\n",
    "    plot.add_tools(TapTool(callback=cb_click))\n",
    "    plot.add_tools(WheelZoomTool())\n",
    "\n",
    "    curdoc().add_root(plot)\n",
    "    \n",
    "    # Display mode\n",
    "    if save_name:\n",
    "        output_file(f\"interactive-figures/{save_name}.html\")\n",
    "    else:\n",
    "        output_notebook()\n",
    "\n",
    "    show(plot)\n",
    "\n",
    "    return \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../bids/data-1/results-dask-bag-bids.csv' does not exist: b'../bids/data-1/results-dask-bag-bids.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-566237aa93ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"func\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"worker\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"thread\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"process\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m gantt_tracker(\n",
      "\u001b[0;32m~/Documents/projects/paper-big-data-engines/.venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/paper-big-data-engines/.venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/paper-big-data-engines/.venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/paper-big-data-engines/.venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/paper-big-data-engines/.venv/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../bids/data-1/results-dask-bag-bids.csv' does not exist: b'../bids/data-1/results-dask-bag-bids.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"../bids/data-1/results-dask-bag-bids.csv\"\n",
    "\n",
    "col_name = [\"func\", \"start\", \"end\", \"filename\", \"worker\", \"thread\", \"process\"]\n",
    "df = pd.read_csv(filename, header=None, names=col_name)\n",
    "\n",
    "gantt_tracker(\n",
    "    df,\n",
    "    pre_process=pre_process,\n",
    "    group=\"worker_thread\",\n",
    "    x_limit=800,\n",
    "    save_name=\"dask-bag-bids\",\n",
    "    framework=\"dask\",\n",
    "    xaxis_label=\"Time [s]\",\n",
    "    yaxis_label=\"Worker\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
