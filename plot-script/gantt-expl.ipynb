{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    # Simplify the workers name\n",
    "    df[\"worker_name\"] = df.worker.map(str).map(\n",
    "        lambda x: \"\".join(x.split(\"-\")[1:]).split(\".\")[0]\n",
    "    )\n",
    "\n",
    "    # Rename function\n",
    "    func_map = {\n",
    "        \"read_img\": \"Read\",\n",
    "        \"save_results\": \"Write\",\n",
    "        \"save_histogram\": \"Write\",\n",
    "        \"increment\": \"Compute\",\n",
    "        \"calculate_histogram\": \"Compute\",\n",
    "        \"combine_histogram\": \"Compute\",\n",
    "        \"run_participant\": \"Participant\",\n",
    "        \"run_group\": \"Group\",\n",
    "        \"flatten\": \"Compute\",\n",
    "    }\n",
    "    #     df.func = df.func.apply(lambda x: func_map[x])\n",
    "\n",
    "    # Simplify the thread number for each worker\n",
    "    thread_worker = {\n",
    "        w + \"::\" + str(t): i + 1\n",
    "        for w in df.worker_name.unique()\n",
    "        for i, t in enumerate(df[df.worker_name == w].thread.unique())\n",
    "    }\n",
    "    df[\"worker_thread\"] = df.worker_name.map(str) + \"::\" + df.thread.map(str)\n",
    "    df[\"thread_number\"] = df.worker_thread.map(lambda x: thread_worker[x])\n",
    "    df[\"worker_thread\"] = (\n",
    "        df.worker_name.map(str) + \"::thread\" + df.thread_number.map(str)\n",
    "    )\n",
    "    df = df.sort_values(by=[\"worker_name\", \"thread_number\"], ascending=[False, True])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gantt_tracker(\n",
    "    df,\n",
    "    *,\n",
    "    pre_process=None,\n",
    "    group,\n",
    "    x_limit=None,\n",
    "    save_name=None,\n",
    "    framework,\n",
    "    xaxis_label,\n",
    "    yaxis_label,\n",
    "):\n",
    "    \"\"\"Create an interactive gantt chart from a pandas dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.Dataframe\n",
    "        Data to plot.\n",
    "    pre_process : func\n",
    "        Function to pre-process the dataframe.\n",
    "    group : string, optional\n",
    "        Column name of the element to group together.\n",
    "    x_limit: int, optional\n",
    "        Maximum value for the x axis.\n",
    "    save_name : str, optional\n",
    "        Filename for the gantt chart.\n",
    "    framework : str\n",
    "        Name of the framework from which the data were collected.\n",
    "        Currently only support Dask and Spark.\n",
    "    xaxis_label : str\n",
    "        Label for the x axis.\n",
    "    yaxis_label : str\n",
    "        Label for the y axis.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        DONE\n",
    "    \"\"\"\n",
    "    from bokeh.models import CustomJS, ColumnDataSource, Grid, LinearAxis, Plot, Range1d\n",
    "    from bokeh.models.annotations import Legend, LegendItem\n",
    "    from bokeh.models.glyphs import Quad\n",
    "    from bokeh.models.tools import (\n",
    "        BoxZoomTool,\n",
    "        HoverTool,\n",
    "        PanTool,\n",
    "        ResetTool,\n",
    "        SaveTool,\n",
    "        TapTool,\n",
    "        WheelZoomTool,\n",
    "    )\n",
    "    from bokeh.io import curdoc, output_file, output_notebook, show\n",
    "    from bokeh.palettes import Colorblind8\n",
    "\n",
    "    # Verify that the framework is supported.\n",
    "    try:\n",
    "        if framework.lower() == \"dask\":\n",
    "            pass\n",
    "        elif framework.lower() == \"spark\":\n",
    "            try:\n",
    "                if \"process\" not in df.columns:\n",
    "                    raise ValueError\n",
    "                df[\"thread\"] = df[\"process\"]\n",
    "            except ValueError:\n",
    "                print(\n",
    "                    f\"fatal error : dataframe for spark must contain a process column.\"\n",
    "                )\n",
    "                return\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"fatal error : {framework} is not a supported framework.\")\n",
    "        return\n",
    "\n",
    "    # Pre-processing of the dataframe.\n",
    "    if pre_process:\n",
    "        df = pre_process(df)\n",
    "\n",
    "    # Make sure the dataframe is value with the function standard.\n",
    "    _MUST_HAVE_COLUMN = [\"func\", \"start\", \"end\", \"filename\", \"thread\", group]\n",
    "\n",
    "    for column_name in _MUST_HAVE_COLUMN:\n",
    "        try:\n",
    "            if column_name not in df.columns:\n",
    "                raise ValueError\n",
    "        except ValueError:\n",
    "            print(\n",
    "                f\"fatal error: the dataframe must contain '{column_name}' after the pre-processing.\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "    if x_limit is None:\n",
    "        x_limit = df.end.max()\n",
    "\n",
    "    plot = Plot(\n",
    "        plot_width=1250 if save_name is not None else 800,\n",
    "        plot_height=700 if save_name is not None else 600,\n",
    "        x_range=Range1d(-x_limit * 0.05, x_limit * 1.05, bounds=\"auto\"),\n",
    "        y_range=Range1d(\n",
    "            -max(len(df[group].unique()) * 0.05, 1),\n",
    "            len(df[group].unique()) * 1.05,\n",
    "            bounds=\"auto\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Group the dataframe by user defined group.\n",
    "    # Create label and associate an y-axis value for each group.\n",
    "    y = 0\n",
    "    labels = []\n",
    "    for i, x in enumerate(df.groupby(group, sort=False)):\n",
    "        labels.append(x[0])\n",
    "        df.loc[df.index.isin(x[1].index), \"bottom\"] = y - 0.5\n",
    "        df.loc[df.index.isin(x[1].index), \"top\"] = y + 0.5\n",
    "        y += 1\n",
    "\n",
    "    # Plot overhead\n",
    "    overhead = Quad(\n",
    "        left=0,\n",
    "        right=df.end.max(),\n",
    "        top=(y - 0.5),\n",
    "        bottom=(-0.5),\n",
    "        hatch_pattern=\"@\",\n",
    "        hatch_color=\"red\",\n",
    "        hatch_alpha=0.3,\n",
    "        fill_color=\"red\",\n",
    "        fill_alpha=0.1,\n",
    "        line_color=\"red\",\n",
    "        line_width=0.75,\n",
    "    )\n",
    "\n",
    "    plot.add_glyph(ColumnDataSource({}), overhead)\n",
    "\n",
    "    # Define color map for the functions.\n",
    "    glyphs = list()\n",
    "    for i, x in enumerate(sorted(df.func.unique())):\n",
    "        df.loc[df.func == x, \"color\"] = Colorblind8[i]\n",
    "\n",
    "        glyphs.append(\n",
    "            plot.add_glyph(\n",
    "                ColumnDataSource({}),\n",
    "                Quad(\n",
    "                    fill_color=Colorblind8[i],\n",
    "                    fill_alpha=0.66,\n",
    "                    line_color=Colorblind8[i],\n",
    "                    line_width=0.75,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    df[\"original_color\"] = df[\"color\"]\n",
    "\n",
    "    df[\"runtime\"] = df.end - df.start\n",
    "\n",
    "    source = ColumnDataSource(df)\n",
    "\n",
    "    glyph = Quad(\n",
    "        left=\"start\",\n",
    "        right=\"end\",\n",
    "        top=\"top\",\n",
    "        bottom=\"bottom\",\n",
    "        fill_color=\"color\",\n",
    "        fill_alpha=0.66,\n",
    "        line_color=\"color\",\n",
    "        line_width=0.75,\n",
    "    )\n",
    "\n",
    "    l = plot.add_glyph(source, glyph)\n",
    "\n",
    "    # Legend\n",
    "    legend = Legend(\n",
    "        items=[\n",
    "            LegendItem(label=func, renderers=[glyphs[i]])\n",
    "            for i, func in enumerate(sorted(df.func.unique()))\n",
    "        ]\n",
    "    )\n",
    "    plot.add_layout(legend, \"above\")\n",
    "    plot.legend.orientation = \"horizontal\"\n",
    "\n",
    "    # Axis\n",
    "    xaxis = LinearAxis()\n",
    "    plot.add_layout(xaxis, \"below\")\n",
    "    plot.xaxis.axis_label = xaxis_label\n",
    "\n",
    "    yaxis = LinearAxis()\n",
    "    plot.add_layout(yaxis, \"left\")\n",
    "    plot.yaxis.axis_label = yaxis_label\n",
    "    plot.yaxis.major_label_text_font_size = (\n",
    "        \"6pt\"  # Reduce font size to fit all group together.\n",
    "    )\n",
    "\n",
    "    plot.add_layout(Grid(dimension=0, ticker=xaxis.ticker))\n",
    "    plot.add_layout(Grid(dimension=1, ticker=yaxis.ticker))\n",
    "\n",
    "    # Set y axis tick label\n",
    "    plot.yaxis.ticker = list(range(0, len(labels)))\n",
    "    plot.yaxis.major_label_overrides = {\n",
    "        k: v for k, v in zip(range(0, len(labels)), labels)\n",
    "    }\n",
    "\n",
    "    # Hover tool\n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"filename\", \"@filename\"),\n",
    "            (\"worker\", f\"@{group}\"),\n",
    "            (\"function\", \"@func\"),\n",
    "            (\"runtime\", \"@runtime{%8.3f sec}\"),\n",
    "            (\"start time\", \"@start{%8.3f sec}\"),\n",
    "            (\"end time\", \"@end{%8.3f sec}\"),\n",
    "        ],\n",
    "        formatters={\n",
    "            \"runtime\": \"printf\",\n",
    "            \"start\": \"printf\",\n",
    "            \"end\": \"printf\",\n",
    "        },\n",
    "        attachment=\"left\",\n",
    "    )\n",
    "\n",
    "    # Tap tool custom select\n",
    "    cb_click = CustomJS(\n",
    "        args=dict(source=source),\n",
    "        code=\"\"\"\n",
    "        const inds = source.selected.indices;\n",
    "        const d = source.data;\n",
    "\n",
    "        for (var i = 0; i < d['color'].length; i++){\n",
    "            d['color'][i] = d['original_color'][i]\n",
    "        }\n",
    "\n",
    "        if (inds.length == 0)\n",
    "            return;\n",
    "\n",
    "        same_file = []\n",
    "        for (var i = 0; i < d['color'].length; i++){\n",
    "            if (d['filename'][i] == d['filename'][inds[0]]){\n",
    "                same_file.push(i)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for (var i = 0; i < same_file.length; i++){\n",
    "            d['color'][same_file[i]] = \"firebrick\"\n",
    "        }\n",
    "\n",
    "        source.selected.indices = same_file\n",
    "        source.change.emit();\n",
    "    \"\"\",\n",
    "    )\n",
    "    source.selected.js_on_change(\"indices\", cb_click)\n",
    "\n",
    "    ## Tool\n",
    "    plot.add_tools(BoxZoomTool())\n",
    "    plot.add_tools(hover)\n",
    "    plot.add_tools(PanTool())\n",
    "    plot.add_tools(ResetTool())\n",
    "    plot.add_tools(SaveTool())\n",
    "    plot.add_tools(TapTool(callback=cb_click))\n",
    "    plot.add_tools(WheelZoomTool())\n",
    "\n",
    "    curdoc().add_root(plot)\n",
    "\n",
    "    # Display mode\n",
    "    if save_name:\n",
    "        output_file(f\"interactive-figures/{save_name}.html\")\n",
    "    else:\n",
    "        output_notebook()\n",
    "\n",
    "    show(plot)\n",
    "\n",
    "    return \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"../inc/data-1/results-spark_inc-2node.csv\"\n",
    "\n",
    "col_name = [\"func\", \"start\", \"end\", \"filename\", \"worker\", \"thread\", \"process\"]\n",
    "df = pd.read_csv(filename, header=None, names=col_name)\n",
    "\n",
    "gantt_tracker(\n",
    "    df,\n",
    "    pre_process=pre_process,\n",
    "    group=\"worker_thread\",\n",
    "    x_limit=1400,\n",
    "    save_name=\"spark-histo-showcase\",\n",
    "    framework=\"spark\",\n",
    "    xaxis_label=\"Time [s]\",\n",
    "    yaxis_label=\"Worker\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
